{
    "epoch1": {
        "rightWeight": " ([[ 1.6007-01, -3.2468-02, -1.1956-01],\n        [ 2.4046-02,  1.1785-01, -3.4940-02],\n        [ 1.2790-01,  4.1162-02,  1.5726-01],\n        [ 2.5705-05, -1.5693-01, -9.8416-02]], _=<1>)",
        "leftWeight": "  :\n([[-0.1118, -0.3399,  0.3287],\n        [ 0.4228,  0.5117, -0.1398],\n        [-0.1774, -0.5034,  0.3225],\n        [ 0.3355, -0.0152, -0.2912],\n        [ 0.3277, -0.4807, -0.4216]], _=)",
        "leftBias": "  :\n([0.2337, 0.5073, 0.0360, 0.0987, 0.5683], _=)",
        "modelOut": "tensor([[ 0.1875,  0.5751, -0.0146,  0.1877,  0.6867],\n        [ 0.1794,  0.5827, -0.0389,  0.1152,  0.5342],\n        [ 0.2571,  0.5605,  0.0433,  0.0952,  0.5241],\n        [ 0.2547,  0.4408,  0.0832,  0.1298,  0.6852]],\n       grad_fn=<AddmmBackward0>)",
        "log_probs": "tensor([[-1.7814, -1.3938, -1.9835, -1.7812, -1.2822],\n        [-1.7342, -1.3309, -1.9525, -1.7984, -1.3794],\n        [-1.6712, -1.3678, -1.8850, -1.8331, -1.4042],\n        [-1.6989, -1.5127, -1.8703, -1.8237, -1.2683]],\n       grad_fn=<LogSoftmaxBackward0>)",
        "y_pred": "tensor([[-1.7814, -1.3938, -1.9835, -1.7812, -1.2822],\n        [-1.7342, -1.3309, -1.9525, -1.7984, -1.3794],\n        [-1.6712, -1.3678, -1.8850, -1.8331, -1.4042],\n        [-1.6989, -1.5127, -1.8703, -1.8237, -1.2683]],\n       grad_fn=<LogSoftmaxBackward0>)",
        "loss": "tensor(1.8982, grad_fn=<NllLossBackward0>)"
    },
    "epoch2": {
        "rightWeight": " ([[ 0.1591, -0.0335, -0.1186],\n        [ 0.0230,  0.1169, -0.0339],\n        [ 0.1289,  0.0422,  0.1563],\n        [ 0.0010, -0.1559, -0.0994]], _=<1>)",
        "leftWeight": "  :\n([[-0.1128, -0.3389,  0.3297],\n        [ 0.4218,  0.5127, -0.1388],\n        [-0.1764, -0.5024,  0.3215],\n        [ 0.3365, -0.0162, -0.2902],\n        [ 0.3267, -0.4797, -0.4206]], _=)",
        "leftBias": "  :\n([0.2327, 0.5063, 0.0370, 0.0997, 0.5673], _=)",
        "modelOut": "tensor([[ 0.1870,  0.5727, -0.0124,  0.1882,  0.6852],\n        [ 0.1793,  0.5807, -0.0367,  0.1154,  0.5330],\n        [ 0.2554,  0.5606,  0.0433,  0.0971,  0.5234],\n        [ 0.2526,  0.4406,  0.0832,  0.1315,  0.6842]],\n       grad_fn=<AddmmBackward0>)",
        "log_probs": "tensor([[-1.7812, -1.3955, -1.9806, -1.7800, -1.2830],\n        [-1.7338, -1.3324, -1.9498, -1.7977, -1.3801],\n        [-1.6728, -1.3675, -1.8848, -1.8311, -1.4047],\n        [-1.7005, -1.5125, -1.8699, -1.8216, -1.2689]],\n       grad_fn=<LogSoftmaxBackward0>)",
        "y_pred": "tensor([[-1.7812, -1.3955, -1.9806, -1.7800, -1.2830],\n        [-1.7338, -1.3324, -1.9498, -1.7977, -1.3801],\n        [-1.6728, -1.3675, -1.8848, -1.8311, -1.4047],\n        [-1.7005, -1.5125, -1.8699, -1.8216, -1.2689]],\n       grad_fn=<LogSoftmaxBackward0>)",
        "loss": "tensor(1.8958, grad_fn=<NllLossBackward0>)"
    },
    "epoch3": {
        "rightWeight": " ([[ 0.1581, -0.0345, -0.1176],\n        [ 0.0220,  0.1159, -0.0329],\n        [ 0.0020, -0.1549, -0.1004],\n        [ 0.1299,  0.0432,  0.1553]], _=<1>)",
        "leftWeight": "  :\n([[-0.1138, -0.3379,  0.3307],\n        [ 0.4208,  0.5137, -0.1378],\n        [-0.1754, -0.5014,  0.3205],\n        [ 0.3375, -0.0172, -0.2892],\n        [ 0.3257, -0.4787, -0.4196]], _=)",
        "leftBias": "  :\n([0.2317, 0.5053, 0.0380, 0.1007, 0.5663], _=)",
        "modelOut": "tensor([[ 0.1864,  0.5703, -0.0101,  0.1887,  0.6836],\n        [ 0.1791,  0.5787, -0.0345,  0.1157,  0.5318],\n        [ 0.2506,  0.4404,  0.0831,  0.1331,  0.6832],\n        [ 0.2536,  0.5608,  0.0433,  0.0989,  0.5228]],\n       grad_fn=<AddmmBackward0>)",
        "log_probs": "tensor([[-1.7810, -1.3971, -1.9776, -1.7788, -1.2838],\n        [-1.7335, -1.3339, -1.9471, -1.7969, -1.3808],\n        [-1.7021, -1.5122, -1.8695, -1.8196, -1.2694],\n        [-1.6743, -1.3672, -1.8847, -1.8291, -1.4052]],\n       grad_fn=<LogSoftmaxBackward0>)",
        "y_pred": "tensor([[-1.7810, -1.3971, -1.9776, -1.7788, -1.2838],\n        [-1.7335, -1.3339, -1.9471, -1.7969, -1.3808],\n        [-1.7021, -1.5122, -1.8695, -1.8196, -1.2694],\n        [-1.6743, -1.3672, -1.8847, -1.8291, -1.4052]],\n       grad_fn=<LogSoftmaxBackward0>)",
        "loss": "tensor(1.8933, grad_fn=<NllLossBackward0>)"
    }
}